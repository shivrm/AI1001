\documentclass{article}
\usepackage[preprint]{neurips_2024}

\title{AI1001 - Assignment 2}
\author{Shivram S \\ \texttt{ai24btech11031@iith.ac.in}}

\begin{document}

\maketitle

Go is an ancient Chinese board game. There is only one type of piece, and only one
type of move. Both players place stones on a $19 \times 19$ grid and try to capture
territory by surrounding it with stones. The player with more territory at the end
wins. Go is an important part of South Korean culture. It was one of the four virtues
learnt by literati, along with music, poetry and painting. People think that Go
players are very smart and noble. The game has long been considered a difficult
challenge in the field of artificial intelligence and is considerably more difficult
 to solve than chess.

AlphaGo is an artificial intelligence program made by Google DeepMind to play Go.
It was trained on over 100,000 games of Go
downloaded from the internet. AlphaGo uses deep neural networks, which mimic the
human brain. Such networks were known for several decades, but only became viable
recently due to increases in computing power.

Go is a game that requires a lot of intuition. Machine learning allows AlphaGo to
`learn' the game and play it in new ways that are not obvious to humans. For example,
AlphaGo's goal is to maximize the probability of winning, not the margin by which it
wins. So AlphaGo might play along `slow' routes which do not provide any instantaneous
advantage, but are helpful in the long run.

AlphaGo can be divided into three parts: the policy network which imitates games by
top players, the value network which evaluates a board position and predicts the
probability of winning, and the tree search, which looks through different possible
moves and what they might lead to in the future. First, the policy network scans the
board and finds interesting spots to play. Then, the value network tries to find
the probability that the chosen tree of moves will lead to victory.

AlphaGo has two weaknesses. The first weakness is that the program always takes 60-90s
to make a move, and if it plays along a slow route which can take a large number of
moves to win, it might run out of time. The second weakness is the existence of rarely
occurring positions where the model has not been trained adequately. When the model
enters such a space, it starts playing the wrong moves. 

The documentary also raises concerns about the future of AI development. We see that
people have a tendency to anthropomorphize AI (such as by referring to it as `he' or 
`she'), which is a big obstacle in trying to understand it. Another concern is the 
possibility that AI will attain sentience and turn against humans. But AI is still
a very nascent field, and we are nowhere near that level of sentience. There are already
representatives from large players such as IBM and Microsoft who hold meetings about
the impact of AI and what dangers it could pose, and ensure that AI is used
ethically and responsibly.

The documentary covers AlphaGo's 5-game match against 9 \textbf{dan} (professional) Go player
Lee Sedol. Lee had been playing Go since the age of 8 and had won 18 world
championships. Lee was confident that he would win at least 4 out of the 5 games.
In the first three games, AlphaGo used creative strategies such as
\textbf{peeping} and \textbf{blocking}, forcing Lee into resigning each time.
However, in the fourth game, Lee played a very non-obvious move (called a \textbf{divine move}
by experts), and forced AlphaGo into a space where it had not been trained adequately.
AlphaGo started playing wrong moves, leading to Lee winning the fourth game.
Unfortunately, the fifth game ended in AlphaGo winning, and Lee lost the tournament
1-4 to AlphaGo.

Lee Sedol's tournament against AlphaGo was a major milestone in AI research. After the
tournament, Lee remarked that AlphaGo taught a new way of seeing the
game and that he had found the reason why he plays Go. The tournament led many new
players to discover the game, and increased its popularity worldwide.


\end{document}
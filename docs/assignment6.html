<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Shivram S ai24btech11031@iith.ac.in" />
  <title>AI1001 - Assignment 6</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="style.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">AI1001 - Assignment 6</h1>
<p class="author">Shivram S<br />
<code>ai24btech11031@iith.ac.in</code></p>
</header>
<h1 id="agents-and-environments">Agents and Environments</h1>
<p>An <strong>agent</strong> is a system that perceives its environment
through sensors and acts upon the environment using actuators. What is
perceived by the sensors is called <strong>percept</strong> and the
complete history of percepts is called the agent’s <strong>percept
sequence</strong> An agent’s behaviour is described by an <strong>agent
function</strong>. that maps percepts to actions. This is implemented by
an <strong>agent program</strong>.</p>
<p>A rational agent is one that does the <strong>right thing</strong>.
There are different notions of what the “right thing”, but AI generally
uses the notion of <strong>consequentialism</strong> each action
sequence of the agent is assigned some <strong>desirability</strong>
which is used as a performance measure.</p>
<p>It can be quite hard to formulate a performance measure correctly.
For a vacuum cleaner, we might measure performance by the amount of dirt
cleaned, but an agent might exploit it by creating more dust to maximize
its performance metric.</p>
<p>Rationality depends on four factors - the performance measure, the
agent’s prior knowledge, the allowed actions, and the agent’s percept
sequence. Rationality maximizes an agent’s expected performance, but the
actual outcome of actions can not be predicted, i.e., rationality is not
omniscience. In order to reduce risk of accident, an agent should gather
information through exploration, and learn as much as possible from what
it perceives.</p>
<p>If an agent relies on the designer’s prior knowledge rather than its
own percepts and learning processes, we say that the agent lacks
autonomy. A rational agent should be autonomous, but does not require
complete autonomy from the start. It may be provided with some initial
knowledge as well as an ability to learn. After sufficient experience of
its environment, the behaviour of a rational agent can become
effectively independent of its prior knowledge.</p>
<h1 id="nature-of-environments">Nature of Environments</h1>
<p>When designing an agent, we must consider four attributes - the
performance measure, the environment, the actuators and the sensors. For
example, a self-driving car might be expected to get to the correct
destination, minimize traffic violations, minimize trip time and cost,
and maximise safety and passenger comfort. Some of these goals conflict,
and the agent will have to make tradeoffs.</p>
<p>The environment for a self-driving car may vary from small lanes to
freeways, and the roads may contain obstacles. The actuators might be an
accelerator, a steering, breaking, and a screen to communicate with
passengers. The sensors for the car might include video cameras, lidar
and ultrasound sensors.</p>
<p>Environments may be classified into several categories:</p>
<ul>
<li><p>In a <strong>fully observable</strong> environment, the agent has
access to the complete state of the environment, but not in a
<strong>partially observable</strong> environment. If an agent has no
sensor, then the environment is unobservable.</p></li>
<li><p>If one agent maximizing its performance measure leads to another
agent minimizing its performance measure, then the environment is said
to be <strong>competitive</strong>. If some action collectively
maximizes the performance measure then the environment may be
<strong>co-operative</strong>.</p></li>
<li><p>If the agent can determine the next state of the environment from
the current state and its action, then the environment is said to be
<strong>deterministic</strong>. otherwise it is said to be
<strong>non-deterministic</strong>. A non-deterministic environment is
said to be <strong>stochastic</strong> if the probabilities for each
outcome can be quantified.</p></li>
<li><p>Environments with one agent are called
<strong>single-agent</strong> and those with more than one agent are
said called <strong>multi-agent</strong> environments.</p></li>
<li><p>An environment which has a finite number of discrete states is
<strong>discrete</strong> and an environment whose state sweeps over
values smoothly over time is said to be
<strong>continuous</strong>.</p></li>
<li><p>If the “laws of physics” of the environment are known, then it is
said to be <strong>known</strong> otherwise it is said to be
<strong>unknown</strong>.</p></li>
<li><p>If the environment can change while the agent decides on an
action, then it said to be <strong>dynamic</strong> otherwise it is said
to be <strong>static</strong>.</p></li>
</ul>
</body>
</html>

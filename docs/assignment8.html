<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"  
  "http://www.w3.org/TR/html4/loose.dtd">  
<html > 
<head><title>AI1001 - Assignment 8</title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"> 
<meta name="generator" content="TeX4ht (https://tug.org/tex4ht/)"> 
<meta name="originator" content="TeX4ht (https://tug.org/tex4ht/)"> 
<!-- html --> 
<meta name="src" content="assignment8.tex"> 
<link rel="stylesheet" type="text/css" href="style.css"> 
</head><body 
>
<div class="maketitle">_______________________________________________________________________________________________________________________________________________________________

<h2 class="titleHead">AI1001 - Assignment 8</h2>_____________________________________________________
          <div class="author" ><span 
class="ptmb7t-">Shivram S</span><br /><span 
class="cmtt-10">ai24btech11031@iith.ac.in</span></div>
<br />

       <hr class="float"><div class="float" 
>

       <span 
class="ptmr7t-x-x-90">Preprint. Under review.</span>

       </div><hr class="endfloat" />
       </div>
       <!--l. 13--><p class="noindent" ><span 
class="ptmb7t-">Learning </span>is when an agent improves its performance after making observations about the world. When the
       agent is a computer, we call it <span 
class="ptmb7t-">machine learning </span>a computer observes data, builds a model based on the
       data, and uses the model as a hypothesis about the world and as a piece of software that can solve
       problems.
       <!--l. 18--><p class="noindent" >We want machines to learn because the designers can&#8217;t anticipate all possible future situations, and
       sometimes even the designers have no idea how to program the solution themselves.
       <!--l. 22--><p class="noindent" >Any component of an agent program can be improved by machine learning. The improvements and
       techniques depend on what component is to be improved, what prior knowledge the agent has, and what
       data and feedback is available.
       <!--l. 26--><p class="noindent" >The three main types of learning are classified based on the feedback accompanying the inputs:
              <ul class="itemize1">
              <li class="itemize">
              <!--l. 29--><p class="noindent" >Supervised Learning: The agent observes input-output pairs and learns a function that maps
              from input to output.
              </li>
              <li class="itemize">
              <!--l. 31--><p class="noindent" >Unsupervised Leaning: The agent learns patterns in the input without explicit feedback.
              This is commonly used in <span 
class="ptmb7t-">clustering</span>
              </li>
              <li class="itemize">
              <!--l. 33--><p class="noindent" >Reinforcement  Learning:  The  agent  learns  from  a  series  of  rewards  and  punishments
              (reinforcements). It is up to the agent to decide which actions were responsible for the
              reinforcement.</li></ul>
       <h3 class="sectionHead"><span class="titlemark">1    </span> <a 
 id="x1-10001"></a>Supervised Learning</h3>
       <!--l. 40--><p class="noindent" >In supervised learning, given a training set of example input-output pairs, generated by an unknown
       function <span 
class="cmmi-10">f</span><span 
class="cmr-10">(</span><span 
class="cmmi-10">x</span><span 
class="cmr-10">)</span>, we have to discover a function <span 
class="cmmi-10">h </span>that approximates the true function <span 
class="cmmi-10">f</span>. The function is called
       a <span 
class="ptmb7t-">hypothesis </span>and it is drawn from a <span 
class="ptmb7t-">hypothesis space</span><span 
class="cmsy-10"><img 
src="cmsy10-48.png" alt="H" class="10x-x-48" /> </span>of possible functions. We say that <span 
class="cmmi-10">h </span>is a <span 
class="ptmb7t-">model</span>of
       the data drawn from a <span 
class="ptmb7t-">model class </span><span 
class="cmmi-10">mathcalH</span>.
       <!--l. 46--><p class="noindent" >Ideally, we want a consistent hypothesis, such that <span 
class="cmmi-10">h</span><span 
class="cmr-10">(</span><span 
class="cmmi-10">x</span><sub><span 
class="cmmi-7">i</span></sub><span 
class="cmr-10">) = </span><span 
class="cmmi-10">y</span><sub><span 
class="cmmi-7">i</span></sub> for every <span 
class="cmmi-10">x</span><sub><span 
class="cmmi-7">i</span></sub> in the training set. When this is
       not possible, we look for a <span 
class="ptmb7t-">best-fit function </span>The true measure of a hypothesis is how it handles inputs it has
       not yet seen, i.e. it <span 
class="ptmb7t-">generalizes</span>well. We say that a hypothesis is <span 
class="ptmb7t-">underfitting</span>when it fails to find a pattern in
       the data, and <span 
class="ptmb7t-">overfitting</span>when it performs well on the training data but performs poorly on unseen
       data.
       <!--l. 54--><p class="noindent" >Sometimes, we try to find the hypothesis <span 
class="cmmi-10">h</span><sup><span 
class="cmmi-7">&#x22C6;</span></sup> that is the most probable given the data:
       <!--l. 57--><p class="noindent" >
       <div class="math-display" >
       <img 
src="assignment80x.png" alt="h* = argmax P (h | data)
      h&#x2208;H
       " class="math-display" ></div>

       <!--l. 59--><p class="noindent" >By Bayes&#8217; rule, this is equivalent to
       <!--l. 61--><p class="noindent" >
       <div class="math-display" >
       <img 
src="assignment81x.png" alt="h* = argmax P (data | h)P(h)
      h&#x2208;H
       " class="math-display" ></div>
       <!--l. 63--><p class="noindent" >Hypotheses spaces can be analyzed based on the <span 
class="ptmb7t-">bias</span>they impose, i.e. the tendency of the hypothesis to
       deviate from the expected value over different training sets, and the <span 
class="ptmb7t-">variance</span>they produce,
       i.e the amount of change in the hypothesis due to fluctuation in the training data. There is a
       tradeoff between complex low-bias-high-variance hypotheses and simpler, low-variance-high-bias
       hypotheses.
       <!--l. 69--><p class="noindent" >When we choose a more expressive hypothesis space <span 
class="cmsy-10"><img 
src="cmsy10-48.png" alt="H" class="10x-x-48" /></span>, the computational complexity of finding a good
       hypothesis within that space increases. For example, fitting a straight line to data is easy but fitting a
       high-degree polynomial is harder. Hence, most work on learning has focused on simple representations.
       But, there has also been work on deep learning, which uses a complex representation, but the number of
       steps required to compute <span 
class="cmmi-10">h</span><span 
class="cmr-10">(</span><span 
class="cmmi-10">x</span><span 
class="cmr-10">) </span>is still bounded.
       <!--l. 76--><p class="noindent" >
       <h3 class="sectionHead"><span class="titlemark">2    </span> <a 
 id="x1-20002"></a>Example: Restaurant Waiting</h3>
       <!--l. 78--><p class="noindent" >Suppose we want to solve the problem of deciding whether to wait for a table at a restaurant. The output is a
       boolean variable representing whether we will wait. The input may have several discrete attributes, such
       as:
              <ol  class="enumerate1" >
       <li 
  class="enumerate" id="x1-2002x1">
              <!--l. 83--><p class="noindent" ><span 
class="ptmb7t-">Alternate </span>Whether there is a suitable alternate restaurant nearby
              </li>
       <li 
  class="enumerate" id="x1-2004x2">
              <!--l. 84--><p class="noindent" ><span 
class="ptmb7t-">Bar </span>Whether the restaurant has a comfortable area to wait in
              </li>
       <li 
  class="enumerate" id="x1-2006x3">
              <!--l. 85--><p class="noindent" ><span 
class="ptmb7t-">Fri/Sat </span>True on Fridays and Saturdays
              </li>
       <li 
  class="enumerate" id="x1-2008x4">
              <!--l. 86--><p class="noindent" ><span 
class="ptmb7t-">Hungry </span>Whether we are hungry right now
              </li>
       <li 
  class="enumerate" id="x1-2010x5">
              <!--l. 87--><p class="noindent" ><span 
class="ptmb7t-">Patrons </span>How many people are there in the restaurant

              </li>
       <li 
  class="enumerate" id="x1-2012x6">
              <!--l. 88--><p class="noindent" ><span 
class="ptmb7t-">Price </span>The restaurant&#8217;s price range
              </li>
       <li 
  class="enumerate" id="x1-2014x7">
              <!--l. 89--><p class="noindent" ><span 
class="ptmb7t-">Raining </span>Whether it is raining outside
              </li>
       <li 
  class="enumerate" id="x1-2016x8">
              <!--l. 90--><p class="noindent" ><span 
class="ptmb7t-">Reservation </span>Whether we made a Reservation
              </li>
       <li 
  class="enumerate" id="x1-2018x9">
              <!--l. 91--><p class="noindent" ><span 
class="ptmb7t-">Type </span>The kind of restaurant (French, Italian, Thai, etc.)
              </li>
       <li 
  class="enumerate" id="x1-2020x10">
              <!--l. 92--><p class="noindent" ><span 
class="ptmb7t-">WaitEstimate </span>Host&#8217;s wait time estimate</li></ol>
       <!--l. 95--><p class="noindent" >There are <span 
class="cmr-10">2</span><sup><span 
class="cmr-7">6</span></sup> <span 
class="cmsy-10">&#x00D7; </span><span 
class="cmr-10">3</span><sup><span 
class="cmr-7">2</span></sup> <span 
class="cmsy-10">&#x00D7; </span><span 
class="cmr-10">4</span><sup><span 
class="cmr-7">2</span></sup> <span 
class="cmr-10">= 9</span><span 
class="cmmi-10">,</span><span 
class="cmr-10">216 </span>combinations for the input. Suppose we are given 12 inputs. We have to
       make a best guess for the missing <span 
class="cmr-10">9</span><span 
class="cmmi-10">,</span><span 
class="cmr-10">204 </span>cases using only these 12 examples.
        
</body></html> 




<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Shivram S ai24btech11031@iith.ac.in" />
  <title>AI1001 - Assignment 9</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="style.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">AI1001 - Assignment 9</h1>
<p class="author">Shivram S<br />
<code>ai24btech11031@iith.ac.in</code></p>
</header>
<p>Our goal in machine learning is to select a hypothesis that will
optimally fit future examples. We make the assumption that our future
examples will be like the past, and follow the same probability
distribution <strong>stationarity assumption</strong>, and that every
example is independent of previous examples. Examples that satisfy these
equations are independent and identically distributed (i.i.d.).</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>E</mi><mi>j</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>E</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>E</mi><mrow><mi>j</mi><mo>+</mo><mn>2</mn></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>‚Ä¶</mi></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>E</mi><mi>j</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>E</mi><mi>j</mi></msub><mo>‚à£</mo><msub><mi>E</mi><mrow><mi>j</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>E</mi><mrow><mi>j</mi><mo>‚àí</mo><mn>2</mn></mrow></msub><mo>,</mo><mi>‚Ä¶</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
P(E_j) = E(E_{j+1}) = P(E_{j+2}) = \dots \\
P(E_j) = P(E_j \mid E_{j-1}, E_{j-2}, \dots)
\end{aligned}</annotation></semantics></math></p>
<p>We can say that the optimal hypothesis is the one that minimizes the
<strong>error rate</strong>: the proportion of times that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚â†</mo><mi>y</mi></mrow><annotation encoding="application/x-tex">h(x) \ne y</annotation></semantics></math>
for an
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(x,y)</annotation></semantics></math>.
This is done by measuring the model‚Äôs performance on a <strong>test
set</strong> of examples. To prevent the model from peeking at the test
answers, we split the examples we have into a <strong>training
set</strong> and a <strong>test set</strong>.</p>
<p>Our model class might have some parameters (called
<strong>hyperparameters</strong>) and we might want to find the optimal
values for them. Tuning the hyperparameters by measuring error rates on
the test set is also considered as peeking. So, we can divide our data
data into a <strong>training set</strong> to train the model, a
<strong>validation set</strong> to tune the hyperparameters, and a
<strong>test set</strong> to do an unbiased evaluation.</p>
<p>If we don‚Äôt have enough data, we can use <strong>k-fold cross
validation</strong>. We split the data into
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
equal subsets. We perform
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
rounds of learning. On each round, we use
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi>/</mi><mi>k</mi></mrow><annotation encoding="application/x-tex">1/k</annotation></semantics></math>
of the data as a validation set and the rest as the training set. The
average test score of the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
rounds is used. Popular values of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
are 5 and 10, enough to give a better estimate at a cost of 5 to 10
times longer computation time. When
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">k=n</annotation></semantics></math>
we call it <strong>leave-one-out cross validation</strong> (LOOCV).</p>
<h1 id="model-selection">Model Selection</h1>
<p>Part of model selection is qualitative and subjective. Based on what
we know about the problem, we might prefer some model classes over
others. Then we can qualitatively select the best model class based on
performance on the validation data set.</p>
<p>We can measure the complexity of a model based on attributes such as
the number of nodes in a decision tree or the number of neural network
parameters. The training set error approaches zero as the complexity
increases, but the validation error starts to increase after some point
due to overfitting. Some model classes, such as decision trees, never
recover from overfitting. Others classes such as deep neural networks,
kernel machines, etc. can use the larger capacity fit a larger number of
suitable representations, hence the validation error tends to decrease
as the capacity increases.</p>
<p>Model classes start to overfit as the capacity approaches the point
of interpolation, which is when the model exactly fits all the training
data. This is because the model‚Äôs capacity is concentrated on the
training examples and the remaining capacity is allocated in a way that
is not representative of the training data.</p>
<h1 id="loss-functions">Loss Functions</h1>
<p>In machine learning, it is traditional to express the model‚Äôs
performance in terms of a <strong>loss function</strong> that needs to
be minimized. The loss function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mover><mi>y</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">L(x, y, \hat y)</annotation></semantics></math>
is the amount of utility lost by predicting
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mover><mi>y</mi><mo accent="true">ÃÇ</mo></mover></mrow><annotation encoding="application/x-tex">h(x) = \hat y</annotation></semantics></math>
when the correct answer is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>y</mi></mrow><annotation encoding="application/x-tex">f(x) = y</annotation></semantics></math>.
We can often use a simplified version
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>y</mi><mo>,</mo><mover><mi>y</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">L(y, \hat y)</annotation></semantics></math>
that is independent of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>.</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mover><mi>y</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>U</mi><mi>t</mi><mi>i</mi><mi>l</mi><mi>i</mi><mi>t</mi><mi>y</mi><mrow><mo stretchy="true" form="prefix">(</mo><mrow><mtext mathvariant="normal">result of using </mtext><mspace width="0.333em"></mspace></mrow><mi>y</mi><mrow><mspace width="0.333em"></mspace><mtext mathvariant="normal"> given </mtext><mspace width="0.333em"></mspace></mrow><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚àí</mo><mi>U</mi><mi>t</mi><mi>i</mi><mi>l</mi><mi>i</mi><mi>t</mi><mi>y</mi><mrow><mo stretchy="true" form="prefix">(</mo><mrow><mtext mathvariant="normal">result of using </mtext><mspace width="0.333em"></mspace></mrow><mover><mi>y</mi><mo accent="true">ÃÇ</mo></mover><mrow><mspace width="0.333em"></mspace><mtext mathvariant="normal"> given </mtext><mspace width="0.333em"></mspace></mrow><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">L(x, y, \hat y) = Utility(\text{result of using $y$ given $x$})
- Utility(\text{result of using $\hat y$ given $x$})</annotation></semantics></math></p>
<p>One misclassification might be worse than another. For example, if a
spam-detection algorithm classifies a spam email as non-spam, then it‚Äôs
just a minor annoyance, but if a non-spam email is classified as spam,
then the user might miss an important message. Hence, we might want to
give a larger value to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>n</mi><mi>o</mi><mi>s</mi><mi>p</mi><mi>a</mi><mi>m</mi><mo>,</mo><mi>s</mi><mi>p</mi><mi>a</mi><mi>m</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">L(nospam,spam)</annotation></semantics></math>
than to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mi>p</mi><mi>a</mi><mi>m</mi><mo>,</mo><mi>n</mi><mi>o</mi><mi>s</mi><mi>p</mi><mi>a</mi><mi>m</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">L(spam, nospam)</annotation></semantics></math>.</p>
<p>We consider smaller errors to be better than larger ones. We can
quantititatively implement this using loss functions such as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>L</mi><mn>1</mn></msub><annotation encoding="application/x-tex">L_1</annotation></semantics></math>
loss and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>L</mi><mn>2</mn></msub><annotation encoding="application/x-tex">L_2</annotation></semantics></math>
loss. For discrete-valued inputs, we can use the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>L</mi><mrow><mn>0</mn><mi>/</mi><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">L_{0/1}</annotation></semantics></math>
loss function.</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><msub><mi>L</mi><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>y</mi><mo>,</mo><mover><mi>y</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mo stretchy="false" form="prefix">|</mo><mi>y</mi><mo>‚àí</mo><mover><mi>y</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="false" form="postfix">|</mo></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"><msub><mi>L</mi><mn>2</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>y</mi><mo>,</mo><mover><mi>y</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><mi>y</mi><mo>‚àí</mo><mover><mi>y</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"><msub><mi>L</mi><mrow><mn>0</mn><mi>/</mi><mn>1</mn></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>y</mi><mo>,</mo><mover><mi>y</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mrow><mrow><mtext mathvariant="normal">0 if </mtext><mspace width="0.333em"></mspace></mrow><mrow><mi>y</mi><mo>=</mo><mover><mi>y</mi><mo accent="true">ÃÇ</mo></mover></mrow><mrow><mspace width="0.333em"></mspace><mtext mathvariant="normal"> else 1</mtext></mrow></mrow></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
    L_1(y, \hat y) &amp;= \lvert y - \hat y \rvert \\
    L_2(y, \hat y) &amp;= (y - \hat y)^2 \\
    L_{0/1}(y, \hat y) &amp;= \text{0 if $y = \hat y$ else 1}
\end{aligned}</annotation></semantics></math></p>
<p>To compute the expected loss over all input-output pairs, we define a
probability distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">P(X, Y)</annotation></semantics></math>
over the examples. Then we can define the expected
<strong>generalization loss</strong> over the set of examples
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>‚Ñ∞</mi><annotation encoding="application/x-tex">\mathcal E</annotation></semantics></math>
for a hypothesis
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>h</mi><annotation encoding="application/x-tex">h</annotation></semantics></math>
as:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mi>e</mi><mi>n</mi><mi>L</mi><mi>o</mi><mi>s</mi><msub><mi>s</mi><mi>L</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>h</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><munder><mo>‚àë</mo><mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚àà</mo><mi>‚Ñ∞</mi></mrow></munder><mi>L</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>y</mi><mo>,</mo><mi>h</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚ãÖ</mo><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">GenLoss_L(h) = \sum_{(x, y) \in \mathcal E} L(y, h(x)) \cdot P(x, y)</annotation></semantics></math></p>
<p>The best hypothesis
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>h</mi><mo>*</mo></msup><annotation encoding="application/x-tex">h^*</annotation></semantics></math>
is the one that minimizes expected generalization loss:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>h</mi><mo>*</mo></msup><mo>=</mo><msub><mo>argmin</mo><mrow><mi>h</mi><mo>‚àà</mo><mi>‚Ñã</mi></mrow></msub><mi>G</mi><mi>e</mi><mi>n</mi><mi>L</mi><mi>o</mi><mi>s</mi><msub><mi>s</mi><mi>L</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>h</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">h^* = \mathop{\mathrm{argmin}}_{h \in \mathcal H} GenLoss_L(h)</annotation></semantics></math></p>
<p>Since
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">P(x, y)</annotation></semantics></math>
is not known in most cases, the learning agent can only estimate
generalization loss with <strong>empirical loss</strong> on a set of
examples
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>E</mi><annotation encoding="application/x-tex">E</annotation></semantics></math>
of size
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>.</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mi>m</mi><mi>p</mi><mi>L</mi><mi>o</mi><mi>s</mi><msub><mi>s</mi><mrow><mi>L</mi><mo>,</mo><mi>E</mi></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>h</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><munder><mo>‚àë</mo><mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚àà</mo><mi>E</mi></mrow></munder><mi>L</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>y</mi><mo>,</mo><mi>h</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mfrac><mn>1</mn><mi>N</mi></mfrac></mrow><annotation encoding="application/x-tex">EmpLoss_{L,E} (h) = \sum_{(x, y) \in E} L(y, h(x)) \frac{1}{N}</annotation></semantics></math></p>
<p>The estimated best hypothesis
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mover><mi>h</mi><mo accent="true">ÃÇ</mo></mover><mo>*</mo></msup><annotation encoding="application/x-tex">\hat h^*</annotation></semantics></math>
is the one with the minimum empirical loss:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover><mi>h</mi><mo accent="true">ÃÇ</mo></mover><mo>*</mo></msup><mo>=</mo><msub><mo>argmin</mo><mrow><mi>h</mi><mo>‚àà</mo><mi>‚Ñã</mi></mrow></msub><mi>E</mi><mi>m</mi><mi>p</mi><mi>L</mi><mi>o</mi><mi>s</mi><msub><mi>s</mi><mrow><mi>L</mi><mo>,</mo><mi>E</mi></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>h</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">\hat h^* = \mathop{\mathrm{argmin}}_{h \in \mathcal H} EmpLoss_{L,E}(h).</annotation></semantics></math></p>
<p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mover><mi>h</mi><mo accent="true">ÃÇ</mo></mover><mo>*</mo></msup><annotation encoding="application/x-tex">\hat h^*</annotation></semantics></math>
may differ from the true function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>
due to unrealizability, variance, noise and computational complexity. A
problem is realiizable if the hypothesis space
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>‚Ñã</mi><annotation encoding="application/x-tex">\mathcal H</annotation></semantics></math>
actually contains the true function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>.
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>
may be non-deterministic or noisy - it may return different values of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(x)</annotation></semantics></math>
for the same value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>.</p>
<p>The early years of machine learning concentrated on
<strong>small-scale learning</strong> where the number of training
example ranges from dozens to the low thousands, and generalization loss
usually came from approximation error of not having
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>
in the hypothesis space. Recently there has been a shift towards
<strong>large-scale learning</strong> with millions of examples, where
the generalization loss is dominated by limits of computation.</p>
<h1 id="regularization">Regularization</h1>
<p>Complicated hypotheses have a tendency to overfit.
<strong>Regularization</strong> is the practice of penalizing complex
hypotheses. This is done using a <strong>regularization
function</strong> which depends on the hypothesis space. For example,
for polynomials, a choice of regularization function may be the sum of
squares of coefficients. Taking regularization into account, we can
define the total cost as:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mi>o</mi><mi>s</mi><mi>t</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>h</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>E</mi><mi>m</mi><mi>p</mi><mi>L</mi><mi>o</mi><mi>s</mi><mi>s</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>h</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mi>Œª</mi><mo>√ó</mo><mi>C</mi><mi>o</mi><mi>m</mi><mi>p</mi><mi>l</mi><mi>e</mi><mi>x</mi><mi>i</mi><mi>t</mi><mi>y</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>h</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">Cost(h) = EmpLoss(h) + \lambda \times Complexity(h)</annotation></semantics></math></p>
<p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œª</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>
is a hyperparameter that serves as a conversion rate between loss and
complexity. However, it is possible to avoid the conversion factor by
encoding the hypothesis as a Turing machine program and counting the
number of bits required to encode the data. The <strong>minimum
description length</strong> hypothesis minimizes the total number of
bits required.</p>
<p>Models can also be simplified by reducing the dimensions that they
work with. <strong>Feature selection</strong> can be performed to
discard irrelevant attributes.</p>
<h1 id="hyperparameter-tuning">Hyperparameter Tuning</h1>
<p>We also want to select the best values for hyperparameters. The
simplest approach is <strong>hand-tuning</strong>, where we guess
parameter values based on past experience or intuition. If there are
only a small number of possible values, <strong>grid-search</strong> can
be used, which tries all combinations and sees which performs best on
the validation data. If there are too many combinations, then we might
use <strong>random search</strong> by sampling some values randomly and
repating as long as we are willing to spend the time and resources.</p>
<p><strong>Bayesian Optimization</strong> treats hyperparameter tuning
as a machine learning problem in itself. We think of the vector of
hyperparameters,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtext mathvariant="bold">ùê±</mtext><annotation encoding="application/x-tex">\textbf{x}</annotation></semantics></math>
as an input, and try to find the function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mtext mathvariant="bold">ùê±</mtext><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">y = f(\textbf{x})</annotation></semantics></math>
which minimizes the loss
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>.
Each pair of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mi>y</mi><mo>,</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mtext mathvariant="bold">ùê±</mtext><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(y, f(\textbf{x}))</annotation></semantics></math>
can be used to update our belief about the shape of the function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>.
We want to trade off exploitation (choosing parameter values near a
previous good result) with exploration (trying novel values).</p>
<p>An alternative to Bayesian optimization is
<strong>population-based-training</strong> (PBT). PBT first uses random
search to train a population of models, each with different
hyperparameter values, then training a second generation whose
hyperparameter values are determined by the best-performing values of
the previous generation, plus random mutation.</p>
</body>
</html>
